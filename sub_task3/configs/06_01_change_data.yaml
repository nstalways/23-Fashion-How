init: # 실험 초기 세팅 관련 args
  seed: 2023 # 실험 재구현을 위해 설정
  mode: 'train' # 실행할 코드를 선택할 때 사용
  model_path: './gAIa_CL_model' # 모델을 저장한 경로
  model_file:  # 모델 이름
  epochs: 20 # 학습 에폭
  save_freq: 40 # 모델 저장 주기
  evaluation_iteration: 10 # 평가 반복 횟수(같은 데이터를 여러 번 평가하는 것)
  use_cl: False # continual learning을 적용 여부

data: # 실험에 사용할 데이터 관련 args
  in_file_trn_dialog: './data/task1.ddata.wst.txt' # 학습 DB
  in_file_tst_dialog: './data/sub-task3_validation_dataset/cl_eval_task1.wst.tst' # 평가 DB (변경됨)
  in_file_fashion: './data/mdata.wst.txt.2023.01.26' # 패션 아이템 DB
  in_file_img_feats: './data/extracted_feat.json' # 이미지 feature DB
  subWordEmb_path: './sstm_v0p5_deploy/sstm_v4p49_np_n36134_d128.dat' # ETRI 자체 개발 단어 임베딩 DB
  corr_thres: 0.7 # cos_sim 값을 기반으로 패션 아이템을 교체할 때 사용하는 threshold 값.
  batch_size: 100 # 미니배치 사이즈
  permutation_iteration: 3 # 순열 반복 횟수
  num_augmentation: 5 # 데이터 증강 횟수
  use_multimodal: False # NLP 도메인 이외의 데이터 사용 여부

model: # 실험에 사용할 모델 관련 args
  hops: 3 # MemN2N 레이어 적층 횟수
  mem_size: 16 # MemN2N의 입력 데이터 차원
  key_size: 300 # MemN2N의 출력 차원
  use_batch_norm: False # batch normalization 적용 여부
  use_dropout: True # dropout 적용 여부
  zero_prob: 0.5 # dropout 확률
  eval_node: '[6000,6000,200][2000]' # PolicyNet의 mlp_eval 모델을 구성할 때 사용

optimizer: # 실험에 사용할 optimizer 관련 args
  learning_rate: 0.005 # 학습률
  max_grad_norm: 20.0 # graident clip에 적용할 최대 gradient 값
